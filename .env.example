# Server configuration
HOST=localhost          # The hostname for the server (default is "localhost")
PORT=8081               # The port the server will listen on (default is "8081")

# Language model configuration
LLM_NAME=llama3:latest  # Name of the language model (replace with your model name)
LLM_API=http://localhost:11434/api/generate  # API endpoint for the LLM model

# OLS (OpenShift Lightspeed Service) configuration
OLS_API="http://localhost:8080" # API endpoint for the OLS API

# SSL configuration
SSLMODE=disable         # SSL mode for the server (default is "disable")