# Server configuration
HOST=localhost          # The hostname for the server (default is "localhost")
PORT=8080               # The port the server will listen on (default is "8080")

# Language model configuration
LLM_NAME=llama3:latest  # Name of the language model (replace with your model name)
LLM_API=http://localhost:11434/api/generate  # API endpoint for the LLM model

# SSL configuration
SSLMODE=disable         # SSL mode for the server (default is "disable")